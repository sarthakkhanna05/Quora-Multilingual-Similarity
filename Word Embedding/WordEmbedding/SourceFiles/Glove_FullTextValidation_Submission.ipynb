{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>lang_abv</th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5130fd2cb5</td>\n",
       "      <td>and these comments were considered in formulat...</td>\n",
       "      <td>The rules developed in the interim were put to...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b72532a0b</td>\n",
       "      <td>These are issues that we wrestle with in pract...</td>\n",
       "      <td>Practice groups are not permitted to work on t...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3931fbe82a</td>\n",
       "      <td>Little things like these make a huge differenc...</td>\n",
       "      <td>I tried to accomplish something.</td>\n",
       "      <td>en</td>\n",
       "      <td>French</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5622f0c60b</td>\n",
       "      <td>you know they can't really defend themselves l...</td>\n",
       "      <td>They can't defend themselves because of their ...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86aaa48b45</td>\n",
       "      <td>To play the role as wellThe opportunity to be ...</td>\n",
       "      <td>How can children see how different ethnicities?</td>\n",
       "      <td>en</td>\n",
       "      <td>Thai</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12115</th>\n",
       "      <td>2b78e2a914</td>\n",
       "      <td>The results of even the most well designed epi...</td>\n",
       "      <td>All studies have the same amount of uncertaint...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>7e9943d152</td>\n",
       "      <td>But there are two kinds of  the pleasure of do...</td>\n",
       "      <td>But there are two kinds of the pleasure of doi...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>5085923e6c</td>\n",
       "      <td>The important thing is to realize that it's wa...</td>\n",
       "      <td>It cannot be moved, now or ever.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>fc8e2fd1fe</td>\n",
       "      <td>At the west end is a detailed model of the who...</td>\n",
       "      <td>The model temple complex is at the east end.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>44301dfb14</td>\n",
       "      <td>For himself he chose Atat??rk, or Father of th...</td>\n",
       "      <td>Ataturk was the father of the Turkish nation.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                            premise  \\\n",
       "0      5130fd2cb5  and these comments were considered in formulat...   \n",
       "1      5b72532a0b  These are issues that we wrestle with in pract...   \n",
       "2      3931fbe82a  Little things like these make a huge differenc...   \n",
       "3      5622f0c60b  you know they can't really defend themselves l...   \n",
       "4      86aaa48b45  To play the role as wellThe opportunity to be ...   \n",
       "...           ...                                                ...   \n",
       "12115  2b78e2a914  The results of even the most well designed epi...   \n",
       "12116  7e9943d152  But there are two kinds of  the pleasure of do...   \n",
       "12117  5085923e6c  The important thing is to realize that it's wa...   \n",
       "12118  fc8e2fd1fe  At the west end is a detailed model of the who...   \n",
       "12119  44301dfb14  For himself he chose Atat??rk, or Father of th...   \n",
       "\n",
       "                                              hypothesis lang_abv language  \\\n",
       "0      The rules developed in the interim were put to...       en  English   \n",
       "1      Practice groups are not permitted to work on t...       en  English   \n",
       "2                       I tried to accomplish something.       en   French   \n",
       "3      They can't defend themselves because of their ...       en  English   \n",
       "4        How can children see how different ethnicities?       en     Thai   \n",
       "...                                                  ...      ...      ...   \n",
       "12115  All studies have the same amount of uncertaint...       en  English   \n",
       "12116  But there are two kinds of the pleasure of doi...       en  English   \n",
       "12117                   It cannot be moved, now or ever.       en  English   \n",
       "12118       The model temple complex is at the east end.       en  English   \n",
       "12119      Ataturk was the father of the Turkish nation.       en  English   \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          2  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "...      ...  \n",
       "12115      2  \n",
       "12116      0  \n",
       "12117      2  \n",
       "12118      2  \n",
       "12119      0  \n",
       "\n",
       "[12120 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning each sentence.\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "#will replace the html characters with \" \"\n",
    "    text=re.sub('<.*?>', ' ', text)  \n",
    "    #To remove the punctuations\n",
    "    text = text.translate(str.maketrans(' ',' ',string.punctuation))\n",
    "    #will consider only alphabets and numerics\n",
    "    text = re.sub('[^a-zA-Z]',' ',text)  \n",
    "    #will replace newline with space\n",
    "    text = re.sub(\"\\n\",\" \",text)\n",
    "    #will convert to lower case\n",
    "    text = text.lower()\n",
    "    # will split and join the words\n",
    "    text=' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english['premise_c'] = [clean_text(sentence) for sentence in df_english['premise']] \n",
    "df_english['hypothesis_c'] = [clean_text(sentence) for sentence in df_english['hypothesis']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Look, it's your skin, but you're going to be in trouble if you don't get busy.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english['premise'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'look its your skin but youre going to be in trouble if you dont get busy'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english['premise_c'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english = df_english.drop(columns=['premise', 'hypothesis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Removal of stopwords\n",
    "\n",
    "# from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "# df_english['premise_stop'] = [remove_stopwords(sentence) for sentence in df_english['premise_c']]\n",
    "# df_english['hypo_stop'] = [remove_stopwords(sentence) for sentence in df_english['hypothesis_c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_english['premise_c'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_english['premise_stop'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [and, these, comments, were, considered, in, f...\n",
      "1    [these, are, issues, that, we, wrestle, with, ...\n",
      "2    [little, things, like, these, make, huge, diff...\n",
      "3    [you, know, they, cant, really, defend, themse...\n",
      "4    [to, play, the, role, as, wellthe, opportunity...\n",
      "5    [on, farm, you, may, have, to, cut, these, oxe...\n",
      "6    [when, returning, to, the, united, states, the...\n",
      "7          [from, cockpit, country, to, st, anns, bay]\n",
      "8    [look, its, your, skin, but, youre, going, to,...\n",
      "9    [after, every, one, hundred, degrees, the, pai...\n",
      "Name: tokenized_premise, dtype: object\n",
      "\n",
      "\n",
      "0    [the, rules, developed, in, the, interim, were...\n",
      "1    [practice, groups, are, not, permitted, to, wo...\n",
      "2                   [tried, to, accomplish, something]\n",
      "3    [they, cant, defend, themselves, because, of, ...\n",
      "4    [how, can, children, see, how, different, ethn...\n",
      "5       [people, on, the, farm, use, different, terms]\n",
      "6    [hague, investigations, were, made, by, fbi, p...\n",
      "7          [from, st, anns, bay, to, cockpit, country]\n",
      "8    [the, boss, will, fire, you, if, he, sees, you...\n",
      "9     [the, paint, changes, according, to, the, color]\n",
      "Name: tokenized_hypo, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "# Tokenize the text column to get the new column 'tokenized_text'\n",
    "df_english['tokenized_premise'] = [simple_preprocess(sentence, deacc=True) for sentence in df_english['premise_c']] \n",
    "df_english['tokenized_hypo'] = [simple_preprocess(sentence, deacc=True) for sentence in df_english['hypothesis_c']] \n",
    "print(df_english['tokenized_premise'].head(10))\n",
    "print(\"\\n\")\n",
    "print(df_english['tokenized_hypo'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [and, these, comment, were, consid, in, formul...\n",
      "1    [these, ar, issu, that, we, wrestl, with, in, ...\n",
      "2    [littl, thing, like, these, make, huge, differ...\n",
      "3    [you, know, thei, cant, realli, defend, themse...\n",
      "4    [to, plai, the, role, as, wellth, opportun, to...\n",
      "5    [on, farm, you, mai, have, to, cut, these, oxe...\n",
      "6    [when, return, to, the, unit, state, the, hedg...\n",
      "7           [from, cockpit, countri, to, st, ann, bai]\n",
      "8    [look, it, your, skin, but, your, go, to, be, ...\n",
      "9    [after, everi, on, hundr, degre, the, paint, s...\n",
      "Name: stemmed_premise, dtype: object\n",
      "0    [the, rule, develop, in, the, interim, were, p...\n",
      "1    [practic, group, ar, not, permit, to, work, on...\n",
      "2                        [tri, to, accomplish, someth]\n",
      "3    [thei, cant, defend, themselv, becaus, of, the...\n",
      "4       [how, can, children, see, how, differ, ethnic]\n",
      "5             [peopl, on, the, farm, us, differ, term]\n",
      "6     [hagu, investig, were, made, by, fbi, personnel]\n",
      "7           [from, st, ann, bai, to, cockpit, countri]\n",
      "8    [the, boss, will, fire, you, if, he, see, you,...\n",
      "9          [the, paint, chang, accord, to, the, color]\n",
      "Name: stemmed_hypo, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "# Get the stemmed_tokens\n",
    "df_english['stemmed_premise'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in df_english['tokenized_premise']]\n",
    "print(df_english['stemmed_premise'].head(10))\n",
    "df_english['stemmed_hypo'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in df_english['tokenized_hypo']]\n",
    "print(df_english['stemmed_hypo'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_english[['stemmed_premise', 'stemmed_hypo']], \n",
    "                                                    df_english['label'], \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index()\n",
    "X_test = X_test.reset_index()\n",
    "Y_train = Y_train.to_frame()\n",
    "Y_train = Y_train.reset_index()\n",
    "Y_test = Y_test.to_frame()\n",
    "Y_test = Y_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3368\n",
      "2    3237\n",
      "1    3091\n",
      "Name: label, dtype: int64\n",
      "2    827\n",
      "0    808\n",
      "1    789\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_train['label'].value_counts())\n",
    "print(Y_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\n",
    "\n",
    "Here, we use: Common Crawl (42B tokens, 1.9M vocab, uncased, 300d vectors, 1.75 GB download) GloVe pre-trained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pre-trained vectors into dictionary that hold mappings between words and the embedding vectors\n",
    "import numpy as np\n",
    "embeddings_dict = {}\n",
    "\n",
    "with open(\"glove.42B.300d.txt\", 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.6884e-01, -1.7578e-01,  4.5401e-02, -3.4579e-01,  8.3458e-02,\n",
       "        4.5321e-02, -3.2051e+00,  4.2430e-01, -2.9677e-01, -3.3661e-02,\n",
       "        1.3370e-01,  4.4926e-01,  1.5338e-01,  2.8428e-01, -1.1154e-01,\n",
       "        4.9325e-03,  1.8104e-01, -7.4951e-01,  3.4237e-02, -6.6673e-01,\n",
       "       -8.3367e-02,  1.2997e-01, -4.7923e-01, -1.0729e-01,  1.9265e-02,\n",
       "       -1.4062e-01,  7.9975e-02, -1.9749e-01, -1.6811e-01,  1.1539e-01,\n",
       "       -2.6112e-01,  4.5084e-01, -3.7895e-01,  3.2797e-01, -6.8369e-01,\n",
       "       -5.7115e-02, -4.5942e-01,  1.5110e-01, -3.0112e-01, -4.0784e-01,\n",
       "        3.6336e-02,  4.1883e-02,  5.1948e-01,  4.3310e-02, -4.5785e-03,\n",
       "        7.5172e-02, -6.2771e-02, -5.3660e-02,  1.0484e-01,  4.8578e-01,\n",
       "        2.3089e-01, -3.7410e-01,  1.6982e-01,  1.0525e-01, -3.8011e-02,\n",
       "        5.0624e-01,  3.2189e-01,  1.4993e-01, -3.9319e-01,  9.9445e-02,\n",
       "       -1.9707e-01,  4.0726e-01,  3.0029e-01, -2.8234e-01, -4.1426e-01,\n",
       "        5.4300e-02,  9.6829e-02,  1.1243e-01,  8.3774e-01,  3.1980e-01,\n",
       "       -8.3176e-01,  6.0566e-03,  2.2647e-01,  5.2784e-02,  1.3959e-01,\n",
       "       -6.5868e-01, -1.4722e-02,  2.7809e-01,  8.3907e-02, -8.1779e-02,\n",
       "        3.6699e-02, -1.3082e+00,  3.3592e-01, -5.5247e-01, -6.1383e-02,\n",
       "       -6.3180e-02,  3.8834e-01, -2.2143e-01,  1.7056e-01,  1.3108e-01,\n",
       "        2.1877e-01, -3.3690e-01, -1.0263e-01,  1.5078e-01,  1.6879e-02,\n",
       "        2.0190e-01, -2.5009e+00,  7.9831e-02,  2.6364e-01, -1.7007e-01,\n",
       "        4.0549e-01,  1.4269e-01,  7.4205e-02, -3.4229e-01,  2.3488e-01,\n",
       "        6.7490e-01, -1.6864e-01, -9.3316e-01, -5.0629e-01, -6.2795e-01,\n",
       "        1.2786e-01,  4.5360e-01,  1.4549e-01, -4.3255e-01,  4.1621e-01,\n",
       "       -3.5675e-01, -3.0739e-01,  8.8606e-02,  2.7011e-01, -1.0473e-01,\n",
       "       -1.3768e-01, -2.2270e-01, -3.2510e-01, -1.4889e-01, -1.3297e-01,\n",
       "        2.8255e-01, -1.8829e-01,  8.8701e-02, -1.7800e-01,  7.5877e-02,\n",
       "       -2.2150e-01, -1.8141e-01, -4.0465e-01, -1.4992e-02,  4.0371e-01,\n",
       "       -2.4641e-01, -1.5825e-02,  1.9287e-01, -1.0390e-01,  1.2438e-02,\n",
       "        2.2652e-01, -9.5868e-02,  1.2312e-01, -7.0940e-01,  2.1431e-02,\n",
       "       -9.0259e-03, -1.3761e-01, -7.4101e-02,  6.1052e-01,  1.5461e-01,\n",
       "        1.3279e-01, -8.6502e-02, -3.6166e-01,  1.5166e-01, -1.7611e-01,\n",
       "        1.0678e-01,  5.3273e-01,  4.5176e-04, -2.9820e-01, -1.0361e-01,\n",
       "       -3.5762e-01, -1.5369e-02, -1.4889e-01, -3.3557e-02, -3.5515e-01,\n",
       "        3.5471e-01, -4.3580e-01, -5.2672e-01,  3.2912e-01, -5.3358e-01,\n",
       "       -3.3422e-02,  3.1608e-01,  6.1683e-02,  7.9933e-01, -4.3619e-02,\n",
       "        6.1413e-01,  1.9004e-01, -6.8713e-02,  8.0825e-03,  2.9881e-01,\n",
       "        6.2538e-01, -1.5442e-01, -3.2420e-02, -2.3852e-01, -1.7233e-01,\n",
       "       -2.8439e-01, -2.3009e-01,  6.1503e-02,  9.7990e-02, -1.3912e-01,\n",
       "        2.4454e-01,  2.1732e-01, -3.0020e-01,  2.0857e-01,  6.5315e-02,\n",
       "       -7.2739e-02, -4.2203e-01,  4.5738e-01, -3.3834e-02, -2.9431e-01,\n",
       "       -2.9015e-01,  1.3171e-01,  1.7338e-01, -2.1529e-01, -3.3860e-02,\n",
       "        1.0072e-01,  1.3231e-01, -6.2709e-01, -2.3567e-01,  4.0249e-01,\n",
       "        2.4637e-01,  4.0739e-01,  2.1072e-01, -6.7639e-02,  3.0044e-01,\n",
       "       -3.5585e-01,  5.4233e-02, -7.8400e-02,  4.2117e-01,  2.3115e-01,\n",
       "       -1.5103e-01, -1.2511e-01,  1.7310e-01, -3.9190e-02, -2.0228e+00,\n",
       "       -3.5663e-01, -5.6551e-01,  1.3831e-01,  2.0617e-03, -4.9909e-01,\n",
       "        1.8770e-01, -2.6089e-01,  1.0783e-01, -1.1861e-01, -1.5221e-01,\n",
       "       -2.9977e-01,  1.9833e-01,  9.4002e-02, -1.8877e-01,  3.2032e-01,\n",
       "       -4.1177e-01,  4.4900e-03,  3.8603e-01, -1.5483e-01,  1.3709e-02,\n",
       "       -1.7729e-01, -3.2633e-01, -2.2133e-01,  2.4323e-01,  6.2422e-01,\n",
       "       -2.5009e-01,  6.8557e-03,  6.4180e-01,  7.2562e-02, -2.9666e-01,\n",
       "        1.3318e-01, -1.8578e-01, -2.5633e-01,  5.1510e-01,  1.1488e-01,\n",
       "        2.4487e-01, -1.6823e-01, -3.4523e-02,  2.2019e-01,  6.9400e-02,\n",
       "        2.1943e-01,  1.5072e-01, -1.9015e-01, -7.4507e-02,  4.3008e-01,\n",
       "       -3.9614e-01,  2.7464e-02,  5.0860e-01,  4.4127e-01,  1.5594e-01,\n",
       "        2.3031e-01,  2.1797e-01,  1.7829e-01, -3.9284e-01,  3.3233e-01,\n",
       "        1.7411e-01,  7.3443e-02,  1.5066e-01, -3.5184e-01,  9.0683e-02,\n",
       "        4.2152e-01,  3.9068e-02, -3.0437e-01, -1.7221e-01,  7.2297e-02,\n",
       "        1.7024e-01, -7.9436e-02,  1.1896e-01, -1.7506e-01,  4.4333e-01,\n",
       "       -2.0586e-01,  2.2518e-01,  6.1715e-02, -1.2641e-01, -2.3714e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['among']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['among'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['vector_p'] = [[] for i in range(9696)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['vector_h'] = [[] for i in range(9696)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['difference'] = [[] for i in range(9696)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>stemmed_premise</th>\n",
       "      <th>stemmed_hypo</th>\n",
       "      <th>vector_p</th>\n",
       "      <th>vector_h</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10818</td>\n",
       "      <td>[adrin, third, lesson]</td>\n",
       "      <td>[adrin, had, three, lesson]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1955</td>\n",
       "      <td>[the, santa, monica, pier, is, the, coastal, s...</td>\n",
       "      <td>[the, santa, monica, pier, host, free, summer,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6840</td>\n",
       "      <td>[the, cut, will, take, the, biggest, bite, out...</td>\n",
       "      <td>[on, particular, network, of, lawyer, who, pro...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10710</td>\n",
       "      <td>[true, to, hi, word, to, hi, faith, mare, cada...</td>\n",
       "      <td>[cadaan, kept, hi, word, to, grai, cloud, and,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7898</td>\n",
       "      <td>[why, do, not, call, address, larg, cup, of, c...</td>\n",
       "      <td>[can, not, drink, milk]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9691</th>\n",
       "      <td>7813</td>\n",
       "      <td>[we, start, with, the, fine, review, of, shock...</td>\n",
       "      <td>[the, show, about, ey, diseas, wa, tragic]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9692</th>\n",
       "      <td>10955</td>\n",
       "      <td>[will, never, be, dous, brit, hume, fox, new, ...</td>\n",
       "      <td>[thei, did, not, think, anyth, wa, wrong, with...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9693</th>\n",
       "      <td>905</td>\n",
       "      <td>[as, long, as, you, do, not, oppos, yourself, ...</td>\n",
       "      <td>[the, tenyearold, kid, know, what, thei, ar, t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9694</th>\n",
       "      <td>5192</td>\n",
       "      <td>[addition, gao, now, us, by, most, major, fede...</td>\n",
       "      <td>[gao, system, is, rank, the, best, by, most, f...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9695</th>\n",
       "      <td>235</td>\n",
       "      <td>[the, leland, act, simplifi, the, household, d...</td>\n",
       "      <td>[the, household, definit, can, be, simplifi]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9696 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                    stemmed_premise  \\\n",
       "0     10818                             [adrin, third, lesson]   \n",
       "1      1955  [the, santa, monica, pier, is, the, coastal, s...   \n",
       "2      6840  [the, cut, will, take, the, biggest, bite, out...   \n",
       "3     10710  [true, to, hi, word, to, hi, faith, mare, cada...   \n",
       "4      7898  [why, do, not, call, address, larg, cup, of, c...   \n",
       "...     ...                                                ...   \n",
       "9691   7813  [we, start, with, the, fine, review, of, shock...   \n",
       "9692  10955  [will, never, be, dous, brit, hume, fox, new, ...   \n",
       "9693    905  [as, long, as, you, do, not, oppos, yourself, ...   \n",
       "9694   5192  [addition, gao, now, us, by, most, major, fede...   \n",
       "9695    235  [the, leland, act, simplifi, the, household, d...   \n",
       "\n",
       "                                           stemmed_hypo vector_p vector_h  \\\n",
       "0                           [adrin, had, three, lesson]       []       []   \n",
       "1     [the, santa, monica, pier, host, free, summer,...       []       []   \n",
       "2     [on, particular, network, of, lawyer, who, pro...       []       []   \n",
       "3     [cadaan, kept, hi, word, to, grai, cloud, and,...       []       []   \n",
       "4                               [can, not, drink, milk]       []       []   \n",
       "...                                                 ...      ...      ...   \n",
       "9691         [the, show, about, ey, diseas, wa, tragic]       []       []   \n",
       "9692  [thei, did, not, think, anyth, wa, wrong, with...       []       []   \n",
       "9693  [the, tenyearold, kid, know, what, thei, ar, t...       []       []   \n",
       "9694  [gao, system, is, rank, the, best, by, most, f...       []       []   \n",
       "9695       [the, household, definit, can, be, simplifi]       []       []   \n",
       "\n",
       "     difference  \n",
       "0            []  \n",
       "1            []  \n",
       "2            []  \n",
       "3            []  \n",
       "4            []  \n",
       "...         ...  \n",
       "9691         []  \n",
       "9692         []  \n",
       "9693         []  \n",
       "9694         []  \n",
       "9695         []  \n",
       "\n",
       "[9696 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-2efa23d3deb8>:20: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  array_vector_p = np.array(array_vector_p).astype(np.float)\n",
      "<ipython-input-27-2efa23d3deb8>:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  array_vector_h = np.array(array_vector_h).astype(np.float)\n",
      "<ipython-input-27-2efa23d3deb8>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['vector_p'][index] = model_vector_p\n",
      "<ipython-input-27-2efa23d3deb8>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['vector_h'][index] = model_vector_h\n",
      "D:\\Users\\tommy\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "D:\\Users\\tommy\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-27-2efa23d3deb8>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['vector_p'][index] = [int(0) for i in range(300)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_word_vector(token):\n",
    "    if token in embeddings_dict:\n",
    "        return embeddings_dict[token]\n",
    "    else:\n",
    "        return [int(0) for i in range(300)]\n",
    "\n",
    "for index, row in X_train.iterrows():\n",
    "    array_vector_p = []\n",
    "    for token in row['stemmed_premise']:\n",
    "        word_vector = get_word_vector(token)\n",
    "        array_vector_p.append(word_vector)\n",
    "        \n",
    "    array_vector_h = []\n",
    "    for token in row['stemmed_hypo']:\n",
    "        word_vector = get_word_vector(token)\n",
    "        array_vector_h.append(word_vector)\n",
    "        \n",
    "    array_vector_p = np.array(array_vector_p).astype(np.float)\n",
    "    array_vector_h = np.array(array_vector_h).astype(np.float)\n",
    "    \n",
    "#     if(index == 0):\n",
    "#         print(array_vector_p)\n",
    "    model_vector_p = (np.mean(array_vector_p, axis=0)).tolist()\n",
    "    model_vector_h = (np.mean(array_vector_h, axis=0)).tolist()\n",
    "\n",
    "    if type(model_vector_p) is list:  \n",
    "        X_train['vector_p'][index] = model_vector_p\n",
    "    else:\n",
    "        X_train['vector_p'][index] = [int(0) for i in range(300)]\n",
    "        \n",
    "    if type(model_vector_h) is list:  \n",
    "        X_train['vector_h'][index] = model_vector_h\n",
    "    else:\n",
    "        X_train['vector_h'][index] = [int(0) for i in range(300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9696 entries, 0 to 9695\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   index            9696 non-null   int64 \n",
      " 1   stemmed_premise  9696 non-null   object\n",
      " 2   stemmed_hypo     9696 non-null   object\n",
      " 3   vector_p         9696 non-null   object\n",
      " 4   vector_h         9696 non-null   object\n",
      " 5   difference       9696 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 454.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-37257d207415>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['difference'][index] = np.array(X_train['vector_h'][index]) - np.array(X_train['vector_p'][index])\n"
     ]
    }
   ],
   "source": [
    "for index, row in X_train.iterrows():\n",
    "    X_train['difference'][index] = np.array(X_train['vector_h'][index]) - np.array(X_train['vector_p'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>stemmed_premise</th>\n",
       "      <th>stemmed_hypo</th>\n",
       "      <th>vector_p</th>\n",
       "      <th>vector_h</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10818</td>\n",
       "      <td>[adrin, third, lesson]</td>\n",
       "      <td>[adrin, had, three, lesson]</td>\n",
       "      <td>[-0.09781856571013729, 0.1376779961089293, 0.1...</td>\n",
       "      <td>[-0.01083642418961972, 0.15214974898844957, 0....</td>\n",
       "      <td>[0.08698214152051757, 0.014471752879520267, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1955</td>\n",
       "      <td>[the, santa, monica, pier, is, the, coastal, s...</td>\n",
       "      <td>[the, santa, monica, pier, host, free, summer,...</td>\n",
       "      <td>[-0.09180591836394299, -0.11268338037743456, 0...</td>\n",
       "      <td>[-0.05039939275858077, -0.11848281950435856, 0...</td>\n",
       "      <td>[0.04140652560536222, -0.0057994391269240025, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6840</td>\n",
       "      <td>[the, cut, will, take, the, biggest, bite, out...</td>\n",
       "      <td>[on, particular, network, of, lawyer, who, pro...</td>\n",
       "      <td>[-0.010232846344297285, -0.04066027505323291, ...</td>\n",
       "      <td>[-0.05655371973504467, 0.031835884758038446, 0...</td>\n",
       "      <td>[-0.04632087339074739, 0.07249615981127136, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10710</td>\n",
       "      <td>[true, to, hi, word, to, hi, faith, mare, cada...</td>\n",
       "      <td>[cadaan, kept, hi, word, to, grai, cloud, and,...</td>\n",
       "      <td>[-0.005403428028027217, -0.22463061509742624, ...</td>\n",
       "      <td>[0.04765538412791032, -0.3327679955042325, 0.0...</td>\n",
       "      <td>[0.05305881215593754, -0.10813738040680629, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7898</td>\n",
       "      <td>[why, do, not, call, address, larg, cup, of, c...</td>\n",
       "      <td>[can, not, drink, milk]</td>\n",
       "      <td>[-0.07687746585763403, -0.017043633141407843, ...</td>\n",
       "      <td>[-0.24484275048598647, 0.12177749909460545, 0....</td>\n",
       "      <td>[-0.16796528462835245, 0.13882113223601328, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9691</th>\n",
       "      <td>7813</td>\n",
       "      <td>[we, start, with, the, fine, review, of, shock...</td>\n",
       "      <td>[the, show, about, ey, diseas, wa, tragic]</td>\n",
       "      <td>[-0.03560946251337345, -0.010326614746680627, ...</td>\n",
       "      <td>[0.03257399957094874, -0.10327985935977527, -0...</td>\n",
       "      <td>[0.06818346208432219, -0.09295324461309463, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9692</th>\n",
       "      <td>10955</td>\n",
       "      <td>[will, never, be, dous, brit, hume, fox, new, ...</td>\n",
       "      <td>[thei, did, not, think, anyth, wa, wrong, with...</td>\n",
       "      <td>[-0.0461892302914445, 0.01916083339601755, -0....</td>\n",
       "      <td>[-0.051809848501132086, -0.12725776921098048, ...</td>\n",
       "      <td>[-0.005620618209687588, -0.14641860260699802, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9693</th>\n",
       "      <td>905</td>\n",
       "      <td>[as, long, as, you, do, not, oppos, yourself, ...</td>\n",
       "      <td>[the, tenyearold, kid, know, what, thei, ar, t...</td>\n",
       "      <td>[-0.05653075047302991, 0.044885497889481485, -...</td>\n",
       "      <td>[-0.08129065455351439, 0.031040765345096588, -...</td>\n",
       "      <td>[-0.02475990408048448, -0.013844732544384897, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9694</th>\n",
       "      <td>5192</td>\n",
       "      <td>[addition, gao, now, us, by, most, major, fede...</td>\n",
       "      <td>[gao, system, is, rank, the, best, by, most, f...</td>\n",
       "      <td>[0.04357006999530962, 0.012300073302217893, -0...</td>\n",
       "      <td>[0.07934809222140095, 0.03719918395985256, -0....</td>\n",
       "      <td>[0.035778022226091326, 0.02489911065763467, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9695</th>\n",
       "      <td>235</td>\n",
       "      <td>[the, leland, act, simplifi, the, household, d...</td>\n",
       "      <td>[the, household, definit, can, be, simplifi]</td>\n",
       "      <td>[-0.1107428606067385, -0.07224385972533907, -0...</td>\n",
       "      <td>[-0.0013593317319949467, -0.02221867007513841,...</td>\n",
       "      <td>[0.10938352887474356, 0.05002518965020067, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9696 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                    stemmed_premise  \\\n",
       "0     10818                             [adrin, third, lesson]   \n",
       "1      1955  [the, santa, monica, pier, is, the, coastal, s...   \n",
       "2      6840  [the, cut, will, take, the, biggest, bite, out...   \n",
       "3     10710  [true, to, hi, word, to, hi, faith, mare, cada...   \n",
       "4      7898  [why, do, not, call, address, larg, cup, of, c...   \n",
       "...     ...                                                ...   \n",
       "9691   7813  [we, start, with, the, fine, review, of, shock...   \n",
       "9692  10955  [will, never, be, dous, brit, hume, fox, new, ...   \n",
       "9693    905  [as, long, as, you, do, not, oppos, yourself, ...   \n",
       "9694   5192  [addition, gao, now, us, by, most, major, fede...   \n",
       "9695    235  [the, leland, act, simplifi, the, household, d...   \n",
       "\n",
       "                                           stemmed_hypo  \\\n",
       "0                           [adrin, had, three, lesson]   \n",
       "1     [the, santa, monica, pier, host, free, summer,...   \n",
       "2     [on, particular, network, of, lawyer, who, pro...   \n",
       "3     [cadaan, kept, hi, word, to, grai, cloud, and,...   \n",
       "4                               [can, not, drink, milk]   \n",
       "...                                                 ...   \n",
       "9691         [the, show, about, ey, diseas, wa, tragic]   \n",
       "9692  [thei, did, not, think, anyth, wa, wrong, with...   \n",
       "9693  [the, tenyearold, kid, know, what, thei, ar, t...   \n",
       "9694  [gao, system, is, rank, the, best, by, most, f...   \n",
       "9695       [the, household, definit, can, be, simplifi]   \n",
       "\n",
       "                                               vector_p  \\\n",
       "0     [-0.09781856571013729, 0.1376779961089293, 0.1...   \n",
       "1     [-0.09180591836394299, -0.11268338037743456, 0...   \n",
       "2     [-0.010232846344297285, -0.04066027505323291, ...   \n",
       "3     [-0.005403428028027217, -0.22463061509742624, ...   \n",
       "4     [-0.07687746585763403, -0.017043633141407843, ...   \n",
       "...                                                 ...   \n",
       "9691  [-0.03560946251337345, -0.010326614746680627, ...   \n",
       "9692  [-0.0461892302914445, 0.01916083339601755, -0....   \n",
       "9693  [-0.05653075047302991, 0.044885497889481485, -...   \n",
       "9694  [0.04357006999530962, 0.012300073302217893, -0...   \n",
       "9695  [-0.1107428606067385, -0.07224385972533907, -0...   \n",
       "\n",
       "                                               vector_h  \\\n",
       "0     [-0.01083642418961972, 0.15214974898844957, 0....   \n",
       "1     [-0.05039939275858077, -0.11848281950435856, 0...   \n",
       "2     [-0.05655371973504467, 0.031835884758038446, 0...   \n",
       "3     [0.04765538412791032, -0.3327679955042325, 0.0...   \n",
       "4     [-0.24484275048598647, 0.12177749909460545, 0....   \n",
       "...                                                 ...   \n",
       "9691  [0.03257399957094874, -0.10327985935977527, -0...   \n",
       "9692  [-0.051809848501132086, -0.12725776921098048, ...   \n",
       "9693  [-0.08129065455351439, 0.031040765345096588, -...   \n",
       "9694  [0.07934809222140095, 0.03719918395985256, -0....   \n",
       "9695  [-0.0013593317319949467, -0.02221867007513841,...   \n",
       "\n",
       "                                             difference  \n",
       "0     [0.08698214152051757, 0.014471752879520267, -0...  \n",
       "1     [0.04140652560536222, -0.0057994391269240025, ...  \n",
       "2     [-0.04632087339074739, 0.07249615981127136, 0....  \n",
       "3     [0.05305881215593754, -0.10813738040680629, 0....  \n",
       "4     [-0.16796528462835245, 0.13882113223601328, 0....  \n",
       "...                                                 ...  \n",
       "9691  [0.06818346208432219, -0.09295324461309463, -0...  \n",
       "9692  [-0.005620618209687588, -0.14641860260699802, ...  \n",
       "9693  [-0.02475990408048448, -0.013844732544384897, ...  \n",
       "9694  [0.035778022226091326, 0.02489911065763467, -0...  \n",
       "9695  [0.10938352887474356, 0.05002518965020067, 0.1...  \n",
       "\n",
       "[9696 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train[['difference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = []\n",
    "# Converting the tokens into the format that the model requires\n",
    "for index, row in X_train_final.iterrows():\n",
    "    # Converting the tokens into the format that the model requires\n",
    "    train_features.append(row['difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9696"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.69821415e-02,  1.44717529e-02, -2.98965850e-02, -1.40602496e-01,\n",
       "       -3.67600024e-02, -3.69533322e-02, -6.16454149e-01, -1.16465343e-01,\n",
       "        1.41498332e-01, -2.41198674e-01,  2.92389171e-01, -7.66130614e-02,\n",
       "       -3.08444978e-02, -6.01583285e-02, -5.86766501e-03,  2.31973339e-01,\n",
       "       -4.59744184e-02, -1.45791921e-01,  1.42727920e-01,  9.52997456e-02,\n",
       "       -3.58774113e-02, -1.62788815e-01, -2.87509157e-02,  7.39875027e-02,\n",
       "        4.42178324e-02, -4.88847497e-02,  1.40359160e-01, -6.71116685e-02,\n",
       "       -9.48470800e-02, -5.41502486e-02, -1.68977575e-01, -4.32935000e-02,\n",
       "        3.59448312e-02, -8.51223326e-02,  4.50875113e-03, -2.61509254e-01,\n",
       "       -1.53153836e-01, -5.67108281e-02,  8.83000220e-03, -1.73167650e-01,\n",
       "       -6.81313282e-02,  6.30850022e-02,  7.07866810e-03,  2.71107511e-02,\n",
       "       -1.26935499e-01, -3.31082320e-02, -3.53647505e-02, -1.49274335e-01,\n",
       "       -5.56844982e-02,  2.18924707e-02, -1.71997247e-01, -3.22620834e-01,\n",
       "       -1.97966738e-03, -2.00647501e-02,  2.10100174e-01,  3.34972491e-02,\n",
       "        2.19923507e-01, -5.86398387e-02, -6.98143315e-02,  1.32356652e-02,\n",
       "        3.18641625e-02, -1.14068498e-01,  2.53168558e-02,  7.32061689e-02,\n",
       "       -1.24647245e-01, -9.69009163e-02,  3.15983351e-02,  3.14700026e-02,\n",
       "       -1.06058332e-01, -5.63319142e-02, -8.48325044e-02, -4.21949973e-02,\n",
       "        2.23928419e-01,  1.82803572e-01,  1.17399575e-03,  3.12252440e-02,\n",
       "        5.91552381e-02,  2.15157586e-01,  3.57655762e-02,  7.85235834e-02,\n",
       "        1.38944250e-01, -1.60564166e-01, -1.52371657e-01, -1.38449972e-02,\n",
       "       -1.14556086e-01,  1.08204582e-01, -5.40059175e-02,  1.73008339e-02,\n",
       "        3.62460856e-02, -1.89041084e-01,  3.44511342e-01,  3.55509988e-02,\n",
       "       -1.14702829e-01,  5.33789992e-02, -6.55400045e-02, -1.49406274e-01,\n",
       "       -2.37686664e-01, -1.25005006e-01,  1.73879157e-02,  1.17420002e-01,\n",
       "        9.77676654e-02,  5.81854758e-02,  3.40581334e-01, -7.91255528e-03,\n",
       "       -1.77727085e-01,  2.11698168e-01, -3.53544276e-02, -2.72819838e-01,\n",
       "        9.36788956e-02, -2.02612162e-01, -1.20222671e-01, -3.11933334e-03,\n",
       "       -1.02858326e-02,  8.26344981e-02, -4.62099165e-02,  2.42388997e-01,\n",
       "       -1.00308667e-01,  1.89104751e-01,  2.31876417e-01,  8.76946626e-02,\n",
       "        5.81869073e-02,  1.20453307e-02, -6.15166749e-03, -8.96875026e-02,\n",
       "       -1.45674252e-01,  1.57017869e-01, -8.57315833e-02, -5.35216679e-02,\n",
       "       -1.22200327e-01, -5.68917505e-02, -1.82667077e-01,  8.19099955e-02,\n",
       "       -1.04892749e-01,  1.84550670e-01, -1.41802500e-01,  1.29492503e-01,\n",
       "        1.54238368e-02,  1.66094118e-03,  6.53391673e-02,  1.45650509e-01,\n",
       "        1.31908360e-02,  7.85194986e-02,  1.58050048e-02, -8.95939991e-02,\n",
       "        1.70820828e-01, -3.80198316e-02,  2.38197753e-01, -2.81899164e-01,\n",
       "        1.83600917e-01, -7.28777496e-02,  1.93105831e-01,  3.65839146e-02,\n",
       "        5.32883319e-02, -1.65836001e-01, -4.30903320e-02, -1.31630418e-01,\n",
       "        6.07299954e-02, -1.06403167e-01, -9.08608325e-02,  3.85000433e-03,\n",
       "       -1.61552832e-01,  1.55716607e-03, -5.38311712e-02, -9.78326425e-04,\n",
       "        6.81901673e-02,  1.68730161e-01,  7.42693321e-02, -2.52281919e-01,\n",
       "        1.59698922e-01, -9.12286614e-02,  1.89979185e-02, -5.38572508e-02,\n",
       "       -5.76449838e-03,  1.18989252e-01, -1.00427420e-01,  2.02497495e-01,\n",
       "       -1.11966636e-02, -8.40731595e-02,  6.97909212e-02, -2.17465420e-01,\n",
       "        1.67415879e-02,  1.35875009e-02,  1.64012969e-01, -4.80275005e-02,\n",
       "       -3.45578374e-02,  2.10933542e-03, -1.22060835e-01,  3.00641749e-02,\n",
       "        1.20440837e-01, -2.23527508e-02,  2.35901332e-02, -1.55683004e-01,\n",
       "       -4.01578345e-02, -1.60039162e-01, -3.21389164e-01,  7.79933321e-02,\n",
       "        1.36612834e-01,  2.33911678e-02, -4.07884160e-02, -2.04586831e-01,\n",
       "        1.15824999e-01,  1.53337420e-01,  2.53711668e-01, -1.13332833e-01,\n",
       "       -1.89095835e-01, -8.37861622e-02, -1.02936678e-02, -7.26655869e-02,\n",
       "        2.09667590e-01, -9.38269983e-02,  2.85528277e-02,  4.18149966e-02,\n",
       "        1.73267661e-01, -3.92639674e-01,  5.41186699e-02, -1.16141505e-01,\n",
       "       -2.94125498e-01, -6.40933045e-03,  2.06160336e-01,  3.98912523e-02,\n",
       "        1.32475662e-01, -1.49503753e-01,  1.20844914e-01,  1.47559172e-01,\n",
       "       -6.55492480e-01,  1.31611164e-02,  1.89510417e-01,  9.39372502e-02,\n",
       "       -3.43294218e-02, -6.05550011e-02, -6.22659189e-02,  6.24915809e-02,\n",
       "        1.17994161e-01,  4.78808315e-02,  7.80114157e-02,  1.56264321e-01,\n",
       "        1.41886631e-02, -6.33816719e-02,  1.29012499e-01, -1.45659237e-01,\n",
       "       -7.64171717e-02, -2.81350818e-02,  2.05910999e-02,  8.08666622e-02,\n",
       "        5.62805890e-02,  1.33575747e-01, -3.51825674e-02,  1.72625035e-02,\n",
       "       -2.35981171e-01,  5.17666464e-03,  1.09070749e-01, -7.34283465e-03,\n",
       "        1.71529165e-01,  8.35361636e-02, -1.42183104e-01,  2.31343084e-02,\n",
       "       -8.50350012e-02, -1.45443318e-02,  1.16635840e-01,  1.69516500e-01,\n",
       "       -1.81541757e-01, -1.55876658e-02,  7.28621429e-02,  5.72119923e-02,\n",
       "        2.28071172e-01,  7.93320027e-02, -9.04603302e-02,  2.23169925e-01,\n",
       "       -1.27365830e-01, -1.36508836e-01, -1.47220837e-02,  3.80450065e-02,\n",
       "       -9.67074210e-02, -8.17659980e-02,  8.88925021e-02, -4.74679172e-02,\n",
       "       -3.85799600e-05,  1.91723665e-01,  2.40051327e-01,  3.37180824e-02,\n",
       "        3.61795088e-01,  2.44122503e-01,  2.89003418e-01, -2.13889956e-02,\n",
       "       -2.37631667e-02,  4.44891658e-02, -9.56986633e-02, -1.35311330e-01,\n",
       "        1.22350580e-01,  2.07836410e-01,  7.28871661e-02, -6.67142483e-02,\n",
       "       -2.25698293e-02, -2.80079166e-01,  1.12395000e-01, -2.71506755e-01,\n",
       "       -1.23329588e-01, -8.59566641e-02, -8.42549962e-02,  5.83516235e-02])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=4000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Let us try linear SVC model\n",
    "SVC = LinearSVC(max_iter=4000)\n",
    "SVC.fit(train_features, Y_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators=200)\n",
    "clf2.fit(train_features, Y_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-f69f7a950f12>:16: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  array_vector_p = np.array(array_vector_p).astype(np.float)\n",
      "<ipython-input-38-f69f7a950f12>:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  array_vector_h = np.array(array_vector_h).astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "test_features_p = []\n",
    "test_features_h = []\n",
    "test_features_difference = []\n",
    "for index, row in X_test.iterrows():\n",
    "    array_vector_p = []\n",
    "    for token in row['stemmed_premise']:\n",
    "        word_vector = get_word_vector(token)\n",
    "        array_vector_p.append(word_vector)\n",
    "        \n",
    "    array_vector_h = []\n",
    "    for token in row['stemmed_hypo']:\n",
    "        word_vector = get_word_vector(token)\n",
    "        array_vector_h.append(word_vector)\n",
    "        \n",
    "    array_vector_p = np.array(array_vector_p).astype(np.float)\n",
    "    array_vector_h = np.array(array_vector_h).astype(np.float)\n",
    "    \n",
    "#     if(index == 0):\n",
    "#         print(array_vector_p)\n",
    "    model_vector_p = (np.mean(array_vector_p, axis=0)).tolist()\n",
    "    model_vector_h = (np.mean(array_vector_h, axis=0)).tolist()\n",
    "    \n",
    "    if type(model_vector_p) is list:\n",
    "        test_features_p.append(model_vector_p)\n",
    "    else:\n",
    "        test_features_p.append(np.array([0 for i in range(300)]))\n",
    "        \n",
    "    if type(model_vector_h) is list:\n",
    "        test_features_h.append(model_vector_h)\n",
    "    else:\n",
    "        test_features_h.append(np.array([0 for i in range(300)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_features_h)):\n",
    "    difference = np.array(test_features_h[i]) - np.array(test_features_p[i])\n",
    "    test_features_difference.append(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.48      0.46       808\n",
      "           1       0.42      0.37      0.39       789\n",
      "           2       0.44      0.44      0.44       827\n",
      "\n",
      "    accuracy                           0.43      2424\n",
      "   macro avg       0.43      0.43      0.43      2424\n",
      "weighted avg       0.43      0.43      0.43      2424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_word2vec = clf2.predict(test_features_difference)\n",
    "print(classification_report(Y_test['label'],test_predictions_word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.46      0.43       808\n",
      "           1       0.39      0.32      0.35       789\n",
      "           2       0.51      0.55      0.53       827\n",
      "\n",
      "    accuracy                           0.44      2424\n",
      "   macro avg       0.44      0.44      0.44      2424\n",
      "weighted avg       0.44      0.44      0.44      2424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_word2vec_svc = SVC.predict(test_features_difference)\n",
    "print(classification_report(Y_test['label'],test_predictions_word2vec_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning each sentence.\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "#will replace the html characters with \" \"\n",
    "    text=re.sub('<.*?>', ' ', text)  \n",
    "    #To remove the punctuations\n",
    "    text = text.translate(str.maketrans(' ',' ',string.punctuation))\n",
    "    #will consider only alphabets and numerics\n",
    "    text = re.sub('[^a-zA-Z]',' ',text)  \n",
    "    #will replace newline with space\n",
    "    text = re.sub(\"\\n\",\" \",text)\n",
    "    #will convert to lower case\n",
    "    text = text.lower()\n",
    "    # will split and join the words\n",
    "    text=' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "df_english['premise_c'] = [clean_text(sentence) for sentence in df_english['premise']] \n",
    "df_english['hypothesis_c'] = [clean_text(sentence) for sentence in df_english['hypothesis']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [and, these, comments, were, considered, in, f...\n",
      "1    [these, are, issues, that, we, wrestle, with, ...\n",
      "2    [little, things, like, these, make, huge, diff...\n",
      "3    [you, know, they, cant, really, defend, themse...\n",
      "4    [to, play, the, role, as, wellthe, opportunity...\n",
      "5    [on, farm, you, may, have, to, cut, these, oxe...\n",
      "6    [when, returning, to, the, united, states, the...\n",
      "7          [from, cockpit, country, to, st, anns, bay]\n",
      "8    [look, its, your, skin, but, youre, going, to,...\n",
      "9    [after, every, one, hundred, degrees, the, pai...\n",
      "Name: tokenized_premise, dtype: object\n",
      "\n",
      "\n",
      "0    [the, rules, developed, in, the, interim, were...\n",
      "1    [practice, groups, are, not, permitted, to, wo...\n",
      "2                   [tried, to, accomplish, something]\n",
      "3    [they, cant, defend, themselves, because, of, ...\n",
      "4    [how, can, children, see, how, different, ethn...\n",
      "5       [people, on, the, farm, use, different, terms]\n",
      "6    [hague, investigations, were, made, by, fbi, p...\n",
      "7          [from, st, anns, bay, to, cockpit, country]\n",
      "8    [the, boss, will, fire, you, if, he, sees, you...\n",
      "9     [the, paint, changes, according, to, the, color]\n",
      "Name: tokenized_hypo, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "# Tokenize the text column to get the new column 'tokenized_text'\n",
    "df_english['tokenized_premise'] = [simple_preprocess(sentence, deacc=True) for sentence in df_english['premise_c']] \n",
    "df_english['tokenized_hypo'] = [simple_preprocess(sentence, deacc=True) for sentence in df_english['hypothesis_c']] \n",
    "print(df_english['tokenized_premise'].head(10))\n",
    "print(\"\\n\")\n",
    "print(df_english['tokenized_hypo'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [and, these, comment, were, consid, in, formul...\n",
      "1    [these, ar, issu, that, we, wrestl, with, in, ...\n",
      "2    [littl, thing, like, these, make, huge, differ...\n",
      "3    [you, know, thei, cant, realli, defend, themse...\n",
      "4    [to, plai, the, role, as, wellth, opportun, to...\n",
      "5    [on, farm, you, mai, have, to, cut, these, oxe...\n",
      "6    [when, return, to, the, unit, state, the, hedg...\n",
      "7           [from, cockpit, countri, to, st, ann, bai]\n",
      "8    [look, it, your, skin, but, your, go, to, be, ...\n",
      "9    [after, everi, on, hundr, degre, the, paint, s...\n",
      "Name: stemmed_premise, dtype: object\n",
      "0    [the, rule, develop, in, the, interim, were, p...\n",
      "1    [practic, group, ar, not, permit, to, work, on...\n",
      "2                        [tri, to, accomplish, someth]\n",
      "3    [thei, cant, defend, themselv, becaus, of, the...\n",
      "4       [how, can, children, see, how, differ, ethnic]\n",
      "5             [peopl, on, the, farm, us, differ, term]\n",
      "6     [hagu, investig, were, made, by, fbi, personnel]\n",
      "7           [from, st, ann, bai, to, cockpit, countri]\n",
      "8    [the, boss, will, fire, you, if, he, see, you,...\n",
      "9          [the, paint, chang, accord, to, the, color]\n",
      "Name: stemmed_hypo, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "# Get the stemmed_tokens\n",
    "df_english['stemmed_premise'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in df_english['tokenized_premise']]\n",
    "print(df_english['stemmed_premise'].head(10))\n",
    "df_english['stemmed_hypo'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in df_english['tokenized_hypo']]\n",
    "print(df_english['stemmed_hypo'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_english[['stemmed_premise', 'stemmed_hypo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_english['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-8c555f8b16bb>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['vector_p'] = [[] for i in range(12120)]\n"
     ]
    }
   ],
   "source": [
    "X_train['vector_p'] = [[] for i in range(12120)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-2f4f9c19a8ac>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['vector_h'] = [[] for i in range(12120)]\n"
     ]
    }
   ],
   "source": [
    "X_train['vector_h'] = [[] for i in range(12120)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-611c0d902906>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['difference'] = [[] for i in range(12120)]\n"
     ]
    }
   ],
   "source": [
    "X_train['difference'] = [[] for i in range(12120)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_premise</th>\n",
       "      <th>stemmed_hypo</th>\n",
       "      <th>vector_p</th>\n",
       "      <th>vector_h</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[and, these, comment, were, consid, in, formul...</td>\n",
       "      <td>[the, rule, develop, in, the, interim, were, p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[these, ar, issu, that, we, wrestl, with, in, ...</td>\n",
       "      <td>[practic, group, ar, not, permit, to, work, on...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[littl, thing, like, these, make, huge, differ...</td>\n",
       "      <td>[tri, to, accomplish, someth]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[you, know, thei, cant, realli, defend, themse...</td>\n",
       "      <td>[thei, cant, defend, themselv, becaus, of, the...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[to, plai, the, role, as, wellth, opportun, to...</td>\n",
       "      <td>[how, can, children, see, how, differ, ethnic]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12115</th>\n",
       "      <td>[the, result, of, even, the, most, well, desig...</td>\n",
       "      <td>[all, studi, have, the, same, amount, of, unce...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>[but, there, ar, two, kind, of, the, pleasur, ...</td>\n",
       "      <td>[but, there, ar, two, kind, of, the, pleasur, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>[the, import, thing, is, to, realiz, that, it,...</td>\n",
       "      <td>[it, cannot, be, move, now, or, ever]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>[at, the, west, end, is, detail, model, of, th...</td>\n",
       "      <td>[the, model, templ, complex, is, at, the, east...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>[for, himself, he, chose, atatrk, or, father, ...</td>\n",
       "      <td>[ataturk, wa, the, father, of, the, turkish, n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         stemmed_premise  \\\n",
       "0      [and, these, comment, were, consid, in, formul...   \n",
       "1      [these, ar, issu, that, we, wrestl, with, in, ...   \n",
       "2      [littl, thing, like, these, make, huge, differ...   \n",
       "3      [you, know, thei, cant, realli, defend, themse...   \n",
       "4      [to, plai, the, role, as, wellth, opportun, to...   \n",
       "...                                                  ...   \n",
       "12115  [the, result, of, even, the, most, well, desig...   \n",
       "12116  [but, there, ar, two, kind, of, the, pleasur, ...   \n",
       "12117  [the, import, thing, is, to, realiz, that, it,...   \n",
       "12118  [at, the, west, end, is, detail, model, of, th...   \n",
       "12119  [for, himself, he, chose, atatrk, or, father, ...   \n",
       "\n",
       "                                            stemmed_hypo vector_p vector_h  \\\n",
       "0      [the, rule, develop, in, the, interim, were, p...       []       []   \n",
       "1      [practic, group, ar, not, permit, to, work, on...       []       []   \n",
       "2                          [tri, to, accomplish, someth]       []       []   \n",
       "3      [thei, cant, defend, themselv, becaus, of, the...       []       []   \n",
       "4         [how, can, children, see, how, differ, ethnic]       []       []   \n",
       "...                                                  ...      ...      ...   \n",
       "12115  [all, studi, have, the, same, amount, of, unce...       []       []   \n",
       "12116  [but, there, ar, two, kind, of, the, pleasur, ...       []       []   \n",
       "12117              [it, cannot, be, move, now, or, ever]       []       []   \n",
       "12118  [the, model, templ, complex, is, at, the, east...       []       []   \n",
       "12119  [ataturk, wa, the, father, of, the, turkish, n...       []       []   \n",
       "\n",
       "      difference  \n",
       "0             []  \n",
       "1             []  \n",
       "2             []  \n",
       "3             []  \n",
       "4             []  \n",
       "...          ...  \n",
       "12115         []  \n",
       "12116         []  \n",
       "12117         []  \n",
       "12118         []  \n",
       "12119         []  \n",
       "\n",
       "[12120 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-2efa23d3deb8>:20: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  array_vector_p = np.array(array_vector_p).astype(np.float)\n",
      "<ipython-input-25-2efa23d3deb8>:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  array_vector_h = np.array(array_vector_h).astype(np.float)\n",
      "D:\\Users\\tommy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "D:\\Users\\tommy\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "D:\\Users\\tommy\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_word_vector(token):\n",
    "    if token in embeddings_dict:\n",
    "        return embeddings_dict[token]\n",
    "    else:\n",
    "        return [int(0) for i in range(300)]\n",
    "\n",
    "for index, row in X_train.iterrows():\n",
    "    array_vector_p = []\n",
    "    for token in row['stemmed_premise']:\n",
    "        word_vector = get_word_vector(token)\n",
    "        array_vector_p.append(word_vector)\n",
    "        \n",
    "    array_vector_h = []\n",
    "    for token in row['stemmed_hypo']:\n",
    "        word_vector = get_word_vector(token)\n",
    "        array_vector_h.append(word_vector)\n",
    "        \n",
    "    array_vector_p = np.array(array_vector_p).astype(np.float)\n",
    "    array_vector_h = np.array(array_vector_h).astype(np.float)\n",
    "    \n",
    "#     if(index == 0):\n",
    "#         print(array_vector_p)\n",
    "    model_vector_p = (np.mean(array_vector_p, axis=0)).tolist()\n",
    "    model_vector_h = (np.mean(array_vector_h, axis=0)).tolist()\n",
    "\n",
    "    if type(model_vector_p) is list:  \n",
    "        X_train['vector_p'][index] = model_vector_p\n",
    "    else:\n",
    "        X_train['vector_p'][index] = [int(0) for i in range(300)]\n",
    "        \n",
    "    if type(model_vector_h) is list:  \n",
    "        X_train['vector_h'][index] = model_vector_h\n",
    "    else:\n",
    "        X_train['vector_h'][index] = [int(0) for i in range(300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in X_train.iterrows():\n",
    "    X_train['difference'][index] = np.array(X_train['vector_h'][index]) - np.array(X_train['vector_p'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train[['difference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.03538964217129562, -0.04373978410980531, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.013102304976200685, -0.015111435080567993,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.06420282478659199, 0.12891419539944485, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.1448896550847327, -0.03527369317324722, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.09465186066272391, 0.026113564100164875, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12115</th>\n",
       "      <td>[-0.16916175140733164, -0.03306323992687144, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>[0.033586277146823704, 0.029518273202702394, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>[-0.1072663586985852, 0.14287909978468505, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>[-0.021047497685584754, -0.0078070012645588965...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>[0.06045177327468991, 0.04805414918810129, 0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12120 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              difference\n",
       "0      [-0.03538964217129562, -0.04373978410980531, 0...\n",
       "1      [-0.013102304976200685, -0.015111435080567993,...\n",
       "2      [0.06420282478659199, 0.12891419539944485, 0.0...\n",
       "3      [-0.1448896550847327, -0.03527369317324722, -0...\n",
       "4      [0.09465186066272391, 0.026113564100164875, -0...\n",
       "...                                                  ...\n",
       "12115  [-0.16916175140733164, -0.03306323992687144, -...\n",
       "12116  [0.033586277146823704, 0.029518273202702394, -...\n",
       "12117  [-0.1072663586985852, 0.14287909978468505, -0....\n",
       "12118  [-0.021047497685584754, -0.0078070012645588965...\n",
       "12119  [0.06045177327468991, 0.04805414918810129, 0.2...\n",
       "\n",
       "[12120 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Final_train_features_glove_difference.csv'\n",
    "with open(filename, 'w+') as file:\n",
    "    for index, row in X_train_final.iterrows():\n",
    "        line = \",\".join( [str(vector_element) for vector_element in row['difference']] )\n",
    "        file.write(line)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = []\n",
    "# Converting the tokens into the format that the model requires\n",
    "for index, row in X_train_final.iterrows():\n",
    "    # Converting the tokens into the format that the model requires\n",
    "    train_features.append(row['difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=4000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Let us try linear SVC model\n",
    "SVC = LinearSVC(max_iter=4000)\n",
    "SVC.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>lang_abv</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c6d58c3f69</td>\n",
       "      <td>Boxes, Casey, Rachel, Isaiah, Kelly, Kelly, an...</td>\n",
       "      <td>Casey will not be a memorable, one of Coleman ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cefcc82292</td>\n",
       "      <td>This is what we have advised.</td>\n",
       "      <td>When they are informed of what they should do,...</td>\n",
       "      <td>en</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e98005252c</td>\n",
       "      <td>and this is largely due to the fact that mothe...</td>\n",
       "      <td>Mothers are being directed.</td>\n",
       "      <td>en</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58518c10ba</td>\n",
       "      <td>Dialogue with the Art Development of IMA with ...</td>\n",
       "      <td>IMA works with other organizations because the...</td>\n",
       "      <td>en</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c32b0d16df</td>\n",
       "      <td>She was still there.</td>\n",
       "      <td>We thought she was gone, however, she was left.</td>\n",
       "      <td>en</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>5f90dd59b0</td>\n",
       "      <td>Sleep pledged that the motel researched the qu...</td>\n",
       "      <td>Nimieth is being compensated for the motel inv...</td>\n",
       "      <td>en</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>f357a04e86</td>\n",
       "      <td>The  rock  has a soft texture and can be bough...</td>\n",
       "      <td>The rock is harder than most types of rock.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>1f0ea92118</td>\n",
       "      <td>She is currently existed and takes into accoun...</td>\n",
       "      <td>She was seen as very embarrassing after the en...</td>\n",
       "      <td>en</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>0407b48afb</td>\n",
       "      <td>isn't it i can remember i've only been here ei...</td>\n",
       "      <td>I could see downtown Dallas from where I lived...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>16c2f2ab89</td>\n",
       "      <td>In Hong Kong you can have a plate, or even a w...</td>\n",
       "      <td>It's impossible to have a plate hand-painted t...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5195 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                            premise  \\\n",
       "0     c6d58c3f69  Boxes, Casey, Rachel, Isaiah, Kelly, Kelly, an...   \n",
       "1     cefcc82292                      This is what we have advised.   \n",
       "2     e98005252c  and this is largely due to the fact that mothe...   \n",
       "3     58518c10ba  Dialogue with the Art Development of IMA with ...   \n",
       "4     c32b0d16df                               She was still there.   \n",
       "...          ...                                                ...   \n",
       "5190  5f90dd59b0  Sleep pledged that the motel researched the qu...   \n",
       "5191  f357a04e86  The  rock  has a soft texture and can be bough...   \n",
       "5192  1f0ea92118  She is currently existed and takes into accoun...   \n",
       "5193  0407b48afb  isn't it i can remember i've only been here ei...   \n",
       "5194  16c2f2ab89  In Hong Kong you can have a plate, or even a w...   \n",
       "\n",
       "                                             hypothesis lang_abv language  \n",
       "0     Casey will not be a memorable, one of Coleman ...       en     Urdu  \n",
       "1     When they are informed of what they should do,...       en   Arabic  \n",
       "2                           Mothers are being directed.       en   French  \n",
       "3     IMA works with other organizations because the...       en  Chinese  \n",
       "4       We thought she was gone, however, she was left.       en  Russian  \n",
       "...                                                 ...      ...      ...  \n",
       "5190  Nimieth is being compensated for the motel inv...       en     Urdu  \n",
       "5191        The rock is harder than most types of rock.       en  English  \n",
       "5192  She was seen as very embarrassing after the en...       en  Chinese  \n",
       "5193  I could see downtown Dallas from where I lived...       en  English  \n",
       "5194  It's impossible to have a plate hand-painted t...       en  English  \n",
       "\n",
       "[5195 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-6bc2949fa0ed>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['vector_p'] = [[] for i in range(5195)]\n",
      "<ipython-input-32-6bc2949fa0ed>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['vector_h'] = [[] for i in range(5195)]\n",
      "<ipython-input-32-6bc2949fa0ed>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['difference'] = [[] for i in range(5195)]\n"
     ]
    }
   ],
   "source": [
    "test['premise_c'] = [clean_text(sentence) for sentence in test['premise']] \n",
    "test['hypothesis_c'] = [clean_text(sentence) for sentence in test['hypothesis']] \n",
    "\n",
    "test['tokenized_premise'] = [simple_preprocess(sentence, deacc=True) for sentence in test['premise_c']] \n",
    "test['tokenized_hypo'] = [simple_preprocess(sentence, deacc=True) for sentence in test['hypothesis_c']] \n",
    "\n",
    "test['stemmed_premise'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in test['tokenized_premise']]\n",
    "test['stemmed_hypo'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in test['tokenized_hypo']]\n",
    "\n",
    "X_test = test[['id', 'stemmed_premise', 'stemmed_hypo']]\n",
    "\n",
    "X_test['vector_p'] = [[] for i in range(5195)] \n",
    "X_test['vector_h'] = [[] for i in range(5195)] \n",
    "\n",
    "X_test['difference'] = [[] for i in range(5195)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-9fb1668147af>:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  array_vector_p = np.array(array_vector_p).astype(np.float)\n",
      "<ipython-input-33-9fb1668147af>:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  array_vector_h = np.array(array_vector_h).astype(np.float)\n",
      "D:\\Users\\tommy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "D:\\Users\\tommy\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "D:\\Users\\tommy\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for index, row in X_test.iterrows():\n",
    "    array_vector_p = []\n",
    "    for token in row['stemmed_premise']:\n",
    "        word_vector = get_word_vector(token)\n",
    "        array_vector_p.append(word_vector)\n",
    "        \n",
    "    array_vector_h = []\n",
    "    for token in row['stemmed_hypo']:\n",
    "        word_vector = get_word_vector(token)\n",
    "        array_vector_h.append(word_vector)\n",
    "        \n",
    "    array_vector_p = np.array(array_vector_p).astype(np.float)\n",
    "    array_vector_h = np.array(array_vector_h).astype(np.float)\n",
    "    \n",
    "#     if(index == 0):\n",
    "#         print(array_vector_p)\n",
    "    model_vector_p = (np.mean(array_vector_p, axis=0)).tolist()\n",
    "    model_vector_h = (np.mean(array_vector_h, axis=0)).tolist()\n",
    "\n",
    "    if type(model_vector_p) is list:  \n",
    "        X_test['vector_p'][index] = model_vector_p\n",
    "    else:\n",
    "        X_test['vector_p'][index] = [int(0) for i in range(300)]\n",
    "        \n",
    "    if type(model_vector_h) is list:  \n",
    "        X_test['vector_h'][index] = model_vector_h\n",
    "    else:\n",
    "        X_test['vector_h'][index] = [int(0) for i in range(300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in X_test.iterrows():\n",
    "    X_test['difference'][index] = np.array(X_test['vector_h'][index]) - np.array(X_test['vector_p'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = X_test[['difference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.05872554122918071, -0.05088161691450156, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.3729318038250009, -0.1544571913778782, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.0796165030139188, 0.12618183437734842, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.08588968369197876, 0.1864860634629925, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.01586330389707452, -0.021304167496661336, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>[-0.016363424831070006, 0.15049038059078157, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>[0.2679221229607828, 0.10916943509036149, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>[-0.04557169588386185, 0.2581750723766163, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>[0.009876892867463606, -0.014887703168723319, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>[0.06745509910755432, -0.07244712184288653, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5195 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             difference\n",
       "0     [0.05872554122918071, -0.05088161691450156, 0....\n",
       "1     [-0.3729318038250009, -0.1544571913778782, -0....\n",
       "2     [-0.0796165030139188, 0.12618183437734842, 0.1...\n",
       "3     [0.08588968369197876, 0.1864860634629925, -0.0...\n",
       "4     [-0.01586330389707452, -0.021304167496661336, ...\n",
       "...                                                 ...\n",
       "5190  [-0.016363424831070006, 0.15049038059078157, -...\n",
       "5191  [0.2679221229607828, 0.10916943509036149, -0.1...\n",
       "5192  [-0.04557169588386185, 0.2581750723766163, -0....\n",
       "5193  [0.009876892867463606, -0.014887703168723319, ...\n",
       "5194  [0.06745509910755432, -0.07244712184288653, 0....\n",
       "\n",
       "[5195 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Final_test_features_glove_difference.csv'\n",
    "with open(filename, 'w+') as file:\n",
    "    for index, row in X_test_final.iterrows():\n",
    "        line = \",\".join( [str(vector_element) for vector_element in row['difference']] )\n",
    "        file.write(line)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = []\n",
    "# Converting the tokens into the format that the model requires\n",
    "for index, row in X_test_final.iterrows():\n",
    "    # Converting the tokens into the format that the model requires\n",
    "    test_features.append(row['difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = SVC.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 2, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = np.zeros((5195,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(submission, columns=['id', 'prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission['id'] = X_test_final['id']\n",
    "df_submission['prediction'] = predictions\n",
    "df_submission.to_csv(\"GloVe_Difference_SVC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Also want to make concatenation vectors for feeding into neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stemmed_premise</th>\n",
       "      <th>stemmed_hypo</th>\n",
       "      <th>vector_p</th>\n",
       "      <th>vector_h</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c6d58c3f69</td>\n",
       "      <td>[box, casei, rachel, isaiah, kelli, kelli, and...</td>\n",
       "      <td>[casei, will, not, be, memor, on, of, coleman,...</td>\n",
       "      <td>[0.025445887872662682, 0.031208538092099704, -...</td>\n",
       "      <td>[0.08417142910184339, -0.019673078822401855, 0...</td>\n",
       "      <td>[0.05872554122918071, -0.05088161691450156, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cefcc82292</td>\n",
       "      <td>[thi, is, what, we, have, advis]</td>\n",
       "      <td>[when, thei, ar, inform, of, what, thei, shoul...</td>\n",
       "      <td>[0.20903300369779268, 0.03285398706793785, -0....</td>\n",
       "      <td>[-0.16389880012720823, -0.12160320430994034, -...</td>\n",
       "      <td>[-0.3729318038250009, -0.1544571913778782, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e98005252c</td>\n",
       "      <td>[and, thi, is, larg, due, to, the, fact, that,...</td>\n",
       "      <td>[mother, ar, be, direct]</td>\n",
       "      <td>[0.026904501176128786, 0.06308316625654697, -0...</td>\n",
       "      <td>[-0.05271200183779001, 0.1892650006338954, 0.0...</td>\n",
       "      <td>[-0.0796165030139188, 0.12618183437734842, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58518c10ba</td>\n",
       "      <td>[dialogu, with, the, art, develop, of, ima, wi...</td>\n",
       "      <td>[ima, work, with, other, organ, becaus, thei, ...</td>\n",
       "      <td>[-0.01457180455327034, -0.12424914874136447, -...</td>\n",
       "      <td>[0.07131787913870842, 0.06223691472162803, -0....</td>\n",
       "      <td>[0.08588968369197876, 0.1864860634629925, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c32b0d16df</td>\n",
       "      <td>[she, wa, still, there]</td>\n",
       "      <td>[we, thought, she, wa, gone, howev, she, wa, l...</td>\n",
       "      <td>[0.15068972273729742, 0.16894049663096666, 0.0...</td>\n",
       "      <td>[0.1348264188402229, 0.14763632913430533, 0.04...</td>\n",
       "      <td>[-0.01586330389707452, -0.021304167496661336, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>5f90dd59b0</td>\n",
       "      <td>[sleep, pledg, that, the, motel, research, the...</td>\n",
       "      <td>[nimieth, is, be, compens, for, the, motel, in...</td>\n",
       "      <td>[-0.04146257310640067, -0.23847212735563517, 0...</td>\n",
       "      <td>[-0.057825997937470675, -0.0879817467648536, 0...</td>\n",
       "      <td>[-0.016363424831070006, 0.15049038059078157, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>f357a04e86</td>\n",
       "      <td>[the, rock, ha, soft, textur, and, can, be, bo...</td>\n",
       "      <td>[the, rock, is, harder, than, most, type, of, ...</td>\n",
       "      <td>[-0.02677167713857041, 0.03166423207865311, 0....</td>\n",
       "      <td>[0.24115044582221243, 0.1408336671690146, -0.0...</td>\n",
       "      <td>[0.2679221229607828, 0.10916943509036149, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>1f0ea92118</td>\n",
       "      <td>[she, is, current, exist, and, take, into, acc...</td>\n",
       "      <td>[she, wa, seen, as, veri, embarrass, after, th...</td>\n",
       "      <td>[0.023160604242649343, -0.061677571812955044, ...</td>\n",
       "      <td>[-0.022411091641212504, 0.19649750056366125, -...</td>\n",
       "      <td>[-0.04557169588386185, 0.2581750723766163, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>0407b48afb</td>\n",
       "      <td>[isnt, it, can, rememb, iv, onli, been, here, ...</td>\n",
       "      <td>[could, see, downtown, dalla, from, where, liv...</td>\n",
       "      <td>[0.04152944263208796, -0.0008548527128166623, ...</td>\n",
       "      <td>[0.051406335499551564, -0.01574255588153998, 0...</td>\n",
       "      <td>[0.009876892867463606, -0.014887703168723319, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>16c2f2ab89</td>\n",
       "      <td>[in, hong, kong, you, can, have, plate, or, ev...</td>\n",
       "      <td>[it, imposs, to, have, plate, handpaint, to, y...</td>\n",
       "      <td>[0.058568825013935566, -0.007410644498818061, ...</td>\n",
       "      <td>[0.12602392412148988, -0.07985776634170459, 0....</td>\n",
       "      <td>[0.06745509910755432, -0.07244712184288653, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5195 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                    stemmed_premise  \\\n",
       "0     c6d58c3f69  [box, casei, rachel, isaiah, kelli, kelli, and...   \n",
       "1     cefcc82292                   [thi, is, what, we, have, advis]   \n",
       "2     e98005252c  [and, thi, is, larg, due, to, the, fact, that,...   \n",
       "3     58518c10ba  [dialogu, with, the, art, develop, of, ima, wi...   \n",
       "4     c32b0d16df                            [she, wa, still, there]   \n",
       "...          ...                                                ...   \n",
       "5190  5f90dd59b0  [sleep, pledg, that, the, motel, research, the...   \n",
       "5191  f357a04e86  [the, rock, ha, soft, textur, and, can, be, bo...   \n",
       "5192  1f0ea92118  [she, is, current, exist, and, take, into, acc...   \n",
       "5193  0407b48afb  [isnt, it, can, rememb, iv, onli, been, here, ...   \n",
       "5194  16c2f2ab89  [in, hong, kong, you, can, have, plate, or, ev...   \n",
       "\n",
       "                                           stemmed_hypo  \\\n",
       "0     [casei, will, not, be, memor, on, of, coleman,...   \n",
       "1     [when, thei, ar, inform, of, what, thei, shoul...   \n",
       "2                              [mother, ar, be, direct]   \n",
       "3     [ima, work, with, other, organ, becaus, thei, ...   \n",
       "4     [we, thought, she, wa, gone, howev, she, wa, l...   \n",
       "...                                                 ...   \n",
       "5190  [nimieth, is, be, compens, for, the, motel, in...   \n",
       "5191  [the, rock, is, harder, than, most, type, of, ...   \n",
       "5192  [she, wa, seen, as, veri, embarrass, after, th...   \n",
       "5193  [could, see, downtown, dalla, from, where, liv...   \n",
       "5194  [it, imposs, to, have, plate, handpaint, to, y...   \n",
       "\n",
       "                                               vector_p  \\\n",
       "0     [0.025445887872662682, 0.031208538092099704, -...   \n",
       "1     [0.20903300369779268, 0.03285398706793785, -0....   \n",
       "2     [0.026904501176128786, 0.06308316625654697, -0...   \n",
       "3     [-0.01457180455327034, -0.12424914874136447, -...   \n",
       "4     [0.15068972273729742, 0.16894049663096666, 0.0...   \n",
       "...                                                 ...   \n",
       "5190  [-0.04146257310640067, -0.23847212735563517, 0...   \n",
       "5191  [-0.02677167713857041, 0.03166423207865311, 0....   \n",
       "5192  [0.023160604242649343, -0.061677571812955044, ...   \n",
       "5193  [0.04152944263208796, -0.0008548527128166623, ...   \n",
       "5194  [0.058568825013935566, -0.007410644498818061, ...   \n",
       "\n",
       "                                               vector_h  \\\n",
       "0     [0.08417142910184339, -0.019673078822401855, 0...   \n",
       "1     [-0.16389880012720823, -0.12160320430994034, -...   \n",
       "2     [-0.05271200183779001, 0.1892650006338954, 0.0...   \n",
       "3     [0.07131787913870842, 0.06223691472162803, -0....   \n",
       "4     [0.1348264188402229, 0.14763632913430533, 0.04...   \n",
       "...                                                 ...   \n",
       "5190  [-0.057825997937470675, -0.0879817467648536, 0...   \n",
       "5191  [0.24115044582221243, 0.1408336671690146, -0.0...   \n",
       "5192  [-0.022411091641212504, 0.19649750056366125, -...   \n",
       "5193  [0.051406335499551564, -0.01574255588153998, 0...   \n",
       "5194  [0.12602392412148988, -0.07985776634170459, 0....   \n",
       "\n",
       "                                             difference  \n",
       "0     [0.05872554122918071, -0.05088161691450156, 0....  \n",
       "1     [-0.3729318038250009, -0.1544571913778782, -0....  \n",
       "2     [-0.0796165030139188, 0.12618183437734842, 0.1...  \n",
       "3     [0.08588968369197876, 0.1864860634629925, -0.0...  \n",
       "4     [-0.01586330389707452, -0.021304167496661336, ...  \n",
       "...                                                 ...  \n",
       "5190  [-0.016363424831070006, 0.15049038059078157, -...  \n",
       "5191  [0.2679221229607828, 0.10916943509036149, -0.1...  \n",
       "5192  [-0.04557169588386185, 0.2581750723766163, -0....  \n",
       "5193  [0.009876892867463606, -0.014887703168723319, ...  \n",
       "5194  [0.06745509910755432, -0.07244712184288653, 0....  \n",
       "\n",
       "[5195 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-2af24bd6a17f>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['concat'] = [[] for i in range(5195)]\n",
      "D:\\Users\\tommy\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "X_test['concat'] = [[] for i in range(5195)] \n",
    "for index, row in X_test.iterrows():\n",
    "    X_test['concat'][index] = np.concatenate((np.array(X_test['vector_h'][index]), np.array(X_test['vector_p'][index])), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final_concat = X_test[['concat']]\n",
    "filename = 'Final_test_features_glove_concat.csv'\n",
    "with open(filename, 'w+') as file:\n",
    "    for index, row in X_test_final_concat.iterrows():\n",
    "        line = \",\".join( [str(vector_element) for vector_element in row['concat']] )\n",
    "        file.write(line)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-a7b353ad32a9>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['concat'] = [[] for i in range(12120)]\n"
     ]
    }
   ],
   "source": [
    "X_train['concat'] = [[] for i in range(12120)] \n",
    "for index, row in X_train.iterrows():\n",
    "    X_train['concat'][index] = np.concatenate((np.array(X_train['vector_h'][index]), np.array(X_train['vector_p'][index])), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final_concat = X_train[['concat']]\n",
    "filename = 'Final_train_features_glove_concat.csv'\n",
    "with open(filename, 'w+') as file:\n",
    "    for index, row in X_train_final_concat.iterrows():\n",
    "        line = \",\".join( [str(vector_element) for vector_element in row['concat']] )\n",
    "        file.write(line)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
